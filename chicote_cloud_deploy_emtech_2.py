# -*- coding: utf-8 -*-
"""CHICOTE - CLOUD DEPLOY - EMTECH 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aqrQjmew-Ki_QMPrIjidwiFtr5TJbh40

# **DATASET: RICE LEAF DISEASES DATASET**
"""

#Setup and Data Preparation
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
import cv2
import os
from PIL import Image
import zipfile

print("TensorFlow version:", tf.__version__)

dataset_path = "/content/drive/MyDrive/Emtech FINAL/rice leaf dataset"

def explore_dataset(path):
    print("Dataset Structure:")
    for root, dirs, files in os.walk(path):
        level = root.replace(path, '').count(os.sep)
        indent = ' ' * 2 * level
        print(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 2 * (level + 1)
        for file in files[:3]:
            print(f"{subindent}{file}")
        if len(files) > 3:
            print(f"{subindent}... ({len(files)-3} more files)")

explore_dataset(dataset_path)

#Data Analysis and Visualization
def analyze_dataset(path):
    class_counts = {}
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']

    for class_name in os.listdir(path):
        class_path = os.path.join(path, class_name)
        if os.path.isdir(class_path):
            count = len([f for f in os.listdir(class_path)
                        if any(f.lower().endswith(ext) for ext in image_extensions)])
            class_counts[class_name] = count

    return class_counts

class_distribution = analyze_dataset(os.path.join(dataset_path, 'rice_leaf_diseases'))

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.bar(class_distribution.keys(), class_distribution.values())
plt.title('Class Distribution')
plt.xticks(rotation=45)
plt.ylabel('Number of Images')

plt.subplot(1, 2, 2)
plt.pie(class_distribution.values(), labels=class_distribution.keys(), autopct='%1.1f%%')
plt.title('Class Percentage')

plt.tight_layout()
plt.show()

print("Class Distribution:")
for class_name, count in class_distribution.items():
    print(f"{class_name}: {count} images")

#Data Preprocessing and Augmentation
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

class_names = list(train_generator.class_indices.keys())
num_classes = len(class_names)

print("Classes:", class_names)
print("Number of classes:", num_classes)

#Sample Images Visualization
def plot_sample_images(generator, class_names):
    images, labels = next(generator)

    plt.figure(figsize=(15, 10))
    for i in range(12):
        plt.subplot(3, 4, i+1)
        plt.imshow(images[i])
        class_idx = np.argmax(labels[i])
        plt.title(f'Class: {class_names[class_idx]}')
        plt.axis('off')
    plt.tight_layout()
    plt.show()

plot_sample_images(train_generator, class_names)

#Model Architecture
def create_model(num_classes):
    base_model = tf.keras.applications.MobileNetV2(
        input_shape=(224, 224, 3),
        include_top=False,
        weights='imagenet'
    )

    base_model.trainable = True

    model = tf.keras.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.3),
        layers.Dense(128, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        layers.Dense(num_classes, activation='softmax')
    ])

    return model

model = create_model(num_classes)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

#Training with Callbacks
checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
    "best_rice_leaf_model.h5",
    save_best_only=True,
    monitor='val_accuracy',
    mode='max'
)

early_stopping_cb = tf.keras.callbacks.EarlyStopping(
    patience=10,
    restore_best_weights=True,
    monitor='val_accuracy'
)

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=5,
    min_lr=1e-7
)

#Model Training
history = model.fit(
    train_generator,
    epochs=20,
    validation_data=validation_generator,
    callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr],
    verbose=1
)

#Training History Visualization
plt.figure(figsize=(15, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()

plt.tight_layout()
plt.show()

#Model Evaluation
def evaluate_model(model, generator):
    test_loss, test_accuracy = model.evaluate(generator)
    print(f"Test Accuracy: {test_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}")

    y_pred = model.predict(generator)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true = generator.classes

    return y_true, y_pred_classes

y_true, y_pred_classes = evaluate_model(model, validation_generator)

#Confusion Matrix and Classification Report
plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

print("Classification Report:")
print(classification_report(y_true, y_pred_classes, target_names=class_names))

#Save the Model and Class Names
model.save('rice_leaf_disease_model.h5')

import json
with open('class_names.json', 'w') as f:
    json.dump(class_names, f)

import pickle
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(train_generator.class_indices, f)

print("Model and metadata saved successfully")
print("Class names:", class_names)

import streamlit as st
import tensorflow as tf
from tensorflow import keras
import numpy as np
from PIL import Image
import json
import pickle

st.set_page_config(page_title="Rice Leaf Disease Classifier", layout="wide")

@st.cache_resource
def load_model():
    model = keras.models.load_model('rice_leaf_disease_model.h5')
    return model

@st.cache_resource
def load_class_names():
    with open('class_names.json', 'r') as f:
        class_names = json.load(f)
    return class_names

model = load_model()
class_names = load_class_names()

st.title("Rice Leaf Disease Classification")
st.write("Upload an image of a rice leaf to classify its disease condition")

uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

def preprocess_image(image):
    image = image.resize((224, 224))
    image_array = np.array(image)
    image_array = image_array / 255.0
    image_array = np.expand_dims(image_array, axis=0)
    return image_array

if uploaded_file is not None:
    image = Image.open(uploaded_file)

    col1, col2 = st.columns(2)

    with col1:
        st.image(image, caption="Uploaded Image", use_column_width=True)

    with col2:
        with st.spinner("Classifying..."):
            processed_image = preprocess_image(image)
            predictions = model.predict(processed_image)
            predicted_class = class_names[np.argmax(predictions[0])]
            confidence = np.max(predictions[0])

            st.subheader("Prediction Results")
            st.write(f"**Disease:** {predicted_class}")
            st.write(f"**Confidence:** {confidence:.2%}")

            st.subheader("All Probabilities")
            for i, (class_name, prob) in enumerate(zip(class_names, predictions[0])):
                st.write(f"{class_name}: {prob:.2%}")

st.markdown("---")
st.write("Supported diseases: " + ", ".join(class_names))