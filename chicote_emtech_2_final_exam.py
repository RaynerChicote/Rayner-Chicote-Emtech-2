# -*- coding: utf-8 -*-
"""CHICOTE - EMTECH 2 - FINAL EXAM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EV7MWpO_r-XFhhApVKupaP8VBcEmvODe

# **Dataset: Dog Breeds**
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

import numpy as np
import matplotlib.pyplot as plt
import os
import json
from pathlib import Path

print("TensorFlow version:", tf.__version__)

# Step 2: Set Up Paths and Parameters
dataset_path = "/content/drive/MyDrive/Emtech FINAL/dogbreed"


IMG_HEIGHT = 380
IMG_WIDTH = 380
BATCH_SIZE = 16
EPOCHS_PHASE1 = 15
EPOCHS_PHASE2 = 25

# Step 3: Load Data with Larger Images
train_dataset = tf.keras.utils.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    label_mode='categorical'
)

validation_dataset = tf.keras.utils.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    label_mode='categorical'
)

# Get class names
class_names = train_dataset.class_names
NUM_CLASSES = len(class_names)

print(f"Number of classes: {NUM_CLASSES}")
print(f"Training batches: {len(train_dataset)}")
print(f"Validation batches: {len(validation_dataset)}")
print(f"Approx training samples: {len(train_dataset) * BATCH_SIZE}")
print(f"Approx validation samples: {len(validation_dataset) * BATCH_SIZE}")

# Step 4: Visualize Sample Images
def visualize_dataset_samples(dataset, class_names, title="Dataset Samples", num_samples=12):
    """
    Visualize sample images from the dataset with their labels
    """
    plt.figure(figsize=(15, 12))
    plt.suptitle(title, fontsize=16, fontweight='bold', y=0.95)

    for images, labels in dataset.take(1):
        for i in range(min(num_samples, len(images))):
            plt.subplot(3, 4, i+1)

            # For EfficientNet preprocessed images, we need to denormalize for display
            img = images[i].numpy()

            # Denormalize EfficientNet preprocessing
            img = img - img.min()
            img = img / img.max()

            plt.imshow(img)
            class_idx = tf.argmax(labels[i]).numpy()
            breed_name = class_names[class_idx]

            # Truncate long breed names for better display
            if len(breed_name) > 20:
                breed_name = breed_name[:20] + "..."

            plt.title(f'{breed_name}', fontsize=10, pad=5)
            plt.axis('off')

    plt.tight_layout()
    plt.show()

# Visualize training samples
print(" Sample Training Images:")
visualize_dataset_samples(train_dataset, class_names, "Sample Training Images")

# Visualize validation samples
print(" Sample Validation Images:")
visualize_dataset_samples(validation_dataset, class_names, "Sample Validation Images")

# Step 5: Enhanced Data Augmentation
enhanced_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal_and_vertical"),
    tf.keras.layers.RandomRotation(0.15),
    tf.keras.layers.RandomZoom(0.15),
    tf.keras.layers.RandomContrast(0.2),
])

def prepare_enhanced_dataset(dataset, training=False):
    # EfficientNet preprocessing (scale to [-1, 1])
    dataset = dataset.map(lambda x, y: (tf.keras.applications.efficientnet.preprocess_input(x), y))

    if training:
        dataset = dataset.map(lambda x, y: (enhanced_augmentation(x, training=True), y))

    return dataset

# Apply enhanced preprocessing
enhanced_train_dataset = prepare_enhanced_dataset(train_dataset, training=True)
enhanced_validation_dataset = prepare_enhanced_dataset(validation_dataset, training=False)

# Configure for performance
AUTOTUNE = tf.data.AUTOTUNE
enhanced_train_dataset = enhanced_train_dataset.prefetch(buffer_size=AUTOTUNE)
enhanced_validation_dataset = enhanced_validation_dataset.prefetch(buffer_size=AUTOTUNE)

print("Enhanced datasets prepared!")

# Step 6: Visualize Augmented Images
def visualize_augmented_images(dataset, class_names, num_augmentations=8):
    """
    Visualize how data augmentation transforms images
    """
    plt.figure(figsize=(15, 8))
    plt.suptitle('Data Augmentation Examples', fontsize=16, fontweight='bold')

    # Get one batch
    for images, labels in dataset.take(1):
        original_image = images[0]
        original_label = labels[0]


        plt.subplot(2, 4, 1)
        img_orig = original_image.numpy()

        img_orig = img_orig - img_orig.min()
        img_orig = img_orig / img_orig.max()
        plt.imshow(img_orig)
        class_idx = tf.argmax(original_label).numpy()
        plt.title(f'Original:\n{class_names[class_idx]}', fontsize=10)
        plt.axis('off')


        for i in range(1, 8):
            plt.subplot(2, 4, i+1)

            augmented_batch = enhanced_augmentation(tf.expand_dims(original_image, axis=0), training=True)

            aug_image = augmented_batch[0]
            img_aug = aug_image.numpy()

            img_aug = img_aug - img_aug.min()
            img_aug = img_aug / img_aug.max()
            plt.imshow(img_aug)
            plt.title(f'Augmented #{i}', fontsize=10)
            plt.axis('off')

    plt.tight_layout()
    plt.show()

print(" Data Augmentation Visualization:")
visualize_augmented_images(enhanced_train_dataset, class_names)

# Step 7: Create EfficientNet Model
def create_efficientnet_model():
    # Use EfficientNetB3
    base_model = tf.keras.applications.EfficientNetB3(
        include_top=False,
        weights='imagenet',
        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),
        pooling='avg'
    )

    # Freeze base model initially
    base_model.trainable = False

    model = Sequential([
        base_model,

        # Custom classifier
        Dense(1024, activation='relu'),
        BatchNormalization(),
        Dropout(0.5),

        Dense(512, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),

        Dense(NUM_CLASSES, activation='softmax')
    ])

    return model, base_model

# Create model
model, base_model = create_efficientnet_model()

# Compile with lower learning rate
model.compile(
    optimizer=Adam(learning_rate=0.0005),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("EfficientNet model created!")
model.summary()

# Step 8: Enhanced Callbacks
phase1_checkpoint = "/content/drive/MyDrive/Emtech FINAL/phase1_best_model.keras"
phase2_checkpoint = "/content/drive/MyDrive/Emtech FINAL/phase2_best_model.keras"
final_model_path = "/content/drive/MyDrive/Emtech FINAL/final_improved_model.keras"

phase1_callbacks = [
    ModelCheckpoint(
        phase1_checkpoint,
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    ),
    EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
]

phase2_callbacks = [
    ModelCheckpoint(
        phase2_checkpoint,
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    ),
    EarlyStopping(
        monitor='val_accuracy',
        patience=12,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=6,
        min_lr=1e-8,
        verbose=1
    )
]

print("Enhanced callbacks configured!")

# Step 9: Two-Phase Training (NEW)
print("=" * 60)
print("PHASE 1: Training Classifier Head")
print("=" * 60)

# Phase 1: Train only the classifier (base model frozen)
history_phase1 = model.fit(
    enhanced_train_dataset,
    epochs=EPOCHS_PHASE1,
    validation_data=enhanced_validation_dataset,
    callbacks=phase1_callbacks,
    verbose=1
)

print("Phase 1 completed!")
print("Best validation accuracy in Phase 1:", max(history_phase1.history['val_accuracy']))

# Step 10: Fine-Tuning Phase
print("=" * 60)
print("PHASE 2: Fine-Tuning Entire Model")
print("=" * 60)

# Unfreeze the base model for fine-tuning
base_model.trainable = True

# Freeze early layers, fine-tune later layers
for layer in base_model.layers[:-20]:
    layer.trainable = False

print(f"Number of trainable layers: {sum([layer.trainable for layer in base_model.layers])}")

# Recompile with very low learning rate
model.compile(
    optimizer=Adam(learning_rate=0.00001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Phase 2: Fine-tune the entire model
history_phase2 = model.fit(
    enhanced_train_dataset,
    epochs=EPOCHS_PHASE2,
    validation_data=enhanced_validation_dataset,
    callbacks=phase2_callbacks,
    verbose=1
)

print("Phase 2 completed!")

# Step 11: Visualize Training History
def plot_combined_history(history1, history2):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # Combine histories
    total_epochs = len(history1.history['accuracy']) + len(history2.history['accuracy'])

    # Accuracy plot
    ax1.plot(history1.history['accuracy'], label='Phase 1 Training', color='blue', linestyle='-', linewidth=2)
    ax1.plot(history1.history['val_accuracy'], label='Phase 1 Validation', color='blue', linestyle='--', linewidth=2)
    ax1.plot(range(len(history1.history['accuracy']), total_epochs),
             history2.history['accuracy'], label='Phase 2 Training', color='red', linestyle='-', linewidth=2)
    ax1.plot(range(len(history1.history['val_accuracy']), total_epochs),
             history2.history['val_accuracy'], label='Phase 2 Validation', color='red', linestyle='--', linewidth=2)
    ax1.axvline(x=len(history1.history['accuracy'])-1, color='gray', linestyle=':', alpha=0.7, label='Phase Change')
    ax1.set_title(' Model Accuracy Progress', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(0, 1)

    # Loss plot
    ax2.plot(history1.history['loss'], label='Phase 1 Training', color='blue', linestyle='-', linewidth=2)
    ax2.plot(history1.history['val_loss'], label='Phase 1 Validation', color='blue', linestyle='--', linewidth=2)
    ax2.plot(range(len(history1.history['loss']), total_epochs),
             history2.history['loss'], label='Phase 2 Training', color='red', linestyle='-', linewidth=2)
    ax2.plot(range(len(history1.history['val_loss']), total_epochs),
             history2.history['val_loss'], label='Phase 2 Validation', color='red', linestyle='--', linewidth=2)
    ax2.axvline(x=len(history1.history['loss'])-1, color='gray', linestyle=':', alpha=0.7, label='Phase Change')
    ax2.set_title(' Model Loss Progress', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

# Plot training history
print(" Training Progress Visualization:")
plot_combined_history(history_phase1, history_phase2)

# Final evaluation
final_loss, final_accuracy = model.evaluate(enhanced_validation_dataset, verbose=0)
print(f"\n=== FINAL IMPROVED MODEL RESULTS ===")
print(f" Final Validation Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)")
print(f" Final Validation Loss: {final_loss:.4f}")

# Compare with previous model
previous_accuracy = 0.8559
improvement = final_accuracy - previous_accuracy
print(f" Improvement over previous model: +{improvement:.4f} (+{improvement*100:.2f}%)")

# Step 12: Visualize Predictions on Validation Set
def visualize_predictions(model, dataset, class_names, num_samples=8):
    """
    Visualize model predictions on validation samples
    """
    plt.figure(figsize=(20, 12))
    plt.suptitle(' Model Predictions on Validation Set', fontsize=16, fontweight='bold')

    for images, true_labels in dataset.take(1):
        predictions = model.predict(images, verbose=0)

        for i in range(min(num_samples, len(images))):
            plt.subplot(2, 4, i+1)

            # Display image
            img = images[i].numpy()
            img = img - img.min()
            img = img / img.max()
            plt.imshow(img)

            # Get prediction info
            true_class_idx = tf.argmax(true_labels[i]).numpy()
            pred_class_idx = np.argmax(predictions[i])
            confidence = predictions[i][pred_class_idx]

            true_breed = class_names[true_class_idx]
            pred_breed = class_names[pred_class_idx]

            # Color code: green if correct, red if wrong
            color = 'green' if true_class_idx == pred_class_idx else 'red'
            marker = 'green' if true_class_idx == pred_class_idx else 'red'

            plt.title(f'True: {true_breed}\nPred: {pred_breed}\nConf: {confidence:.3f} {marker}',
                     color=color, fontsize=10, pad=10)
            plt.axis('off')

    plt.tight_layout()
    plt.show()

    # Calculate accuracy for this batch
    correct = 0
    for i in range(len(images)):
        true_class_idx = tf.argmax(true_labels[i]).numpy()
        pred_class_idx = np.argmax(predictions[i])
        if true_class_idx == pred_class_idx:
            correct += 1

    batch_accuracy = correct / len(images)
    print(f" Batch Prediction Accuracy: {batch_accuracy:.3f} ({correct}/{len(images)} correct)")

print(" Model Prediction Visualization:")
visualize_predictions(model, enhanced_validation_dataset, class_names)

# Step 13: Save Improved Model
# Save the final model in native Keras format
model.save(final_model_path)
print(f" Final improved model saved to: {final_model_path}")

# Save in SavedModel format using model.export()
saved_model_path = "/content/drive/MyDrive/Emtech FINAL/improved_dog_breed_savedmodel"
model.export(saved_model_path)
print(f" Model saved in SavedModel format to: {saved_model_path}")

# Save updated class information
class_info = {
    'class_names': class_names,
    'class_indices': {name: i for i, name in enumerate(class_names)},
    'num_classes': NUM_CLASSES,
    'img_height': IMG_HEIGHT,
    'img_width': IMG_WIDTH,
    'model_type': 'EfficientNetB3_Improved',
    'final_accuracy': float(final_accuracy)
}

class_info_path = '/content/drive/MyDrive/Emtech FINAL/improved_class_info.json'
with open(class_info_path, 'w') as f:
    json.dump(class_info, f, indent=2)

print(f" Updated class information saved to: {class_info_path}")

# Step 14: Enhanced Prediction Function with Image Display
def predict_dog_breed_improved(image_path, model, class_names, img_height=380, img_width=380):
    """
    Enhanced prediction function for the improved model with image display
    """
    # Load and preprocess image for EfficientNet
    img = tf.keras.utils.load_img(image_path, target_size=(img_height, img_width))
    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)
    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)

    # Make prediction
    predictions = model.predict(img_array, verbose=0)
    predicted_class_idx = np.argmax(predictions[0])
    confidence = predictions[0][predicted_class_idx]

    # Get top 5 predictions
    top_5_indices = np.argsort(predictions[0])[-5:][::-1]
    top_5_confidences = predictions[0][top_5_indices]
    top_5_breeds = [class_names[i] for i in top_5_indices]

    # Create visualization
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # Show original image
    ax1.imshow(img)
    ax1.set_title(f' Input Image\n', fontsize=14, fontweight='bold')
    ax1.axis('off')

    # Show prediction results
    colors = ['#2E8B57' if i == 0 else '#1E90FF' for i in range(5)]  # Green for top prediction, blue for others

    bars = ax2.barh(range(5), top_5_confidences, color=colors)
    ax2.set_yticks(range(5))
    ax2.set_yticklabels(top_5_breeds, fontsize=11)
    ax2.invert_yaxis()
    ax2.set_xlabel('Confidence Score', fontsize=12)
    ax2.set_title(' Top 5 Breed Predictions', fontsize=14, fontweight='bold')
    ax2.set_xlim(0, 1)

    # Add confidence values on bars
    for i, (bar, conf) in enumerate(zip(bars, top_5_confidences)):
        width = bar.get_width()
        ax2.text(width + 0.01, bar.get_y() + bar.get_height()/2,
                f'{conf:.3f}', ha='left', va='center', fontsize=10)

    plt.tight_layout()
    plt.show()

    # Print detailed results
    print(f"\n FINAL PREDICTION: {class_names[predicted_class_idx]}")
    print(f" Confidence: {confidence:.4f} ({confidence*100:.2f}%)")
    print(f" Prediction Index: {predicted_class_idx}")
    print("\n TOP 5 PREDICTIONS:")
    for i, (breed, conf) in enumerate(zip(top_5_breeds, top_5_confidences)):
        print(f"   {i+1}. {breed:<25} {conf:.4f} ({conf*100:.2f}%)")

    return class_names[predicted_class_idx], confidence

print(" Enhanced prediction function with visualization created!")

# Step 15: Final Summary with Visual Report
print("\n" + "="*80)
print(" IMPROVED DOG BREED CLASSIFICATION - TRAINING COMPLETE ")
print("="*80)

# Create final summary visualization
fig, ax = plt.subplots(1, 1, figsize=(10, 6))
ax.axis('off')

summary_text = [
    " TRAINING SUMMARY REPORT",
    "=" * 40,
    f"  Model Architecture: EfficientNetB3 + Custom Classifier",
    f"  Image Size: {IMG_HEIGHT}x{IMG_WIDTH} pixels",
    f" Training Strategy: Two-Phase (Frozen â†’ Fine-tuned)",
    f" Number of Breeds: {NUM_CLASSES}",
    "",
    " PERFORMANCE RESULTS:",
    f"    Final Validation Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)",
    f"    Previous Model Accuracy: 0.8559 (85.59%)",
    f"    Improvement: +{improvement:.4f} (+{improvement*100:.2f}%)",
    "",
    " SAVED FILES:",
    f"    Model: {final_model_path}",
    f"    Class Info: {class_info_path}",
    f"    Checkpoints: {phase1_checkpoint}, {phase2_checkpoint}"
]

# Performance rating
if final_accuracy >= 0.90:
    performance_rating = " EXCELLENT! (90%+ Accuracy)"
    color = "green"
elif final_accuracy >= 0.87:
    performance_rating = " VERY GOOD! (Significant Improvement)"
    color = "blue"
else:
    performance_rating = " GOOD! (Ready for Production)"
    color = "orange"

summary_text.extend(["", f" PERFORMANCE RATING: {performance_rating}"])

# Display summary
for i, line in enumerate(summary_text):
    if "PERFORMANCE RATING" in line:
        ax.text(0.1, 0.9 - i*0.05, line, fontsize=12, fontweight='bold',
                color=color, transform=ax.transAxes)
    elif any(x in line for x in ["Training Summary", "Performance Result", "Saved Files", "Performance Rating"]):
        ax.text(0.1, 0.9 - i*0.05, line, fontsize=11, fontweight='bold',
                transform=ax.transAxes)
    else:
        ax.text(0.1, 0.9 - i*0.05, line, fontsize=11, transform=ax.transAxes)

plt.title("Dog Breed Classification - Final Report", fontsize=16, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()

print(f"\n Training completed successfully! Your model is ready for use! ")

# Install Streamlit
!pip install streamlit

import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps
import numpy as np
import json

@st.cache(allow_output_mutation=True)
def load_model():
    model = tf.keras.models.load_model('/content/drive/MyDrive/Emtech FINAL/final_improved_model.keras')
    return model

@st.cache(allow_output_mutation=True)
def load_class_info():
    with open('/content/drive/MyDrive/Emtech FINAL/improved_class_info.json', 'r') as f:
        class_info = json.load(f)
    return class_info

# Load model and class info
model = load_model()
class_info = load_class_info()
class_names = class_info['class_names']
IMG_HEIGHT = class_info['img_height']
IMG_WIDTH = class_info['img_width']

st.write("""
# Dog Breed Classification System
""")

st.write(f"**Model Information:**")
st.write(f"- Trained on {len(class_names)} dog breeds")
st.write(f"- Input image size: {IMG_HEIGHT}x{IMG_WIDTH} pixels")
st.write(f"- Model type: EfficientNetB3 Transfer Learning")

file = st.file_uploader("Upload a dog photo", type=["jpg", "jpeg", "png"])

def import_and_predict(image_data, model):
    # Resize image to match model input size
    image = ImageOps.fit(image_data, (IMG_WIDTH, IMG_HEIGHT), Image.LANCZOS)

    # Convert to numpy array and preprocess for EfficientNet
    img = np.asarray(image)
    img = tf.keras.applications.efficientnet.preprocess_input(img)
    img_reshape = img[np.newaxis, ...]

    # Make prediction
    prediction = model.predict(img_reshape)
    return prediction

if file is None:
    st.text("Please upload an image file")
else:
    image = Image.open(file)
    st.image(image, use_column_width=True, caption="Uploaded Image")

    # Make prediction
    with st.spinner('Classifying dog breed...'):
        prediction = import_and_predict(image, model)

    # Get top prediction
    predicted_class_idx = np.argmax(prediction[0])
    confidence = prediction[0][predicted_class_idx]
    predicted_breed = class_names[predicted_class_idx]

    # Display results
    st.subheader("Prediction Results")
    st.write(f"**Predicted Breed:** {predicted_breed}")
    st.write(f"**Confidence:** {confidence:.4f} ({confidence*100:.2f}%)")

    # Show top 5 predictions
    st.subheader("Top 5 Predictions")
    top_5_indices = np.argsort(prediction[0])[-5:][::-1]
    top_5_confidences = prediction[0][top_5_indices]
    top_5_breeds = [class_names[i] for i in top_5_indices]

    for i, (breed, conf) in enumerate(zip(top_5_breeds, top_5_confidences)):
        st.write(f"{i+1}. {breed}: {conf:.4f} ({conf*100:.2f}%)")

    # Confidence threshold warning
    if confidence < 0.5:
        st.warning("Low confidence prediction. The image might not be a dog or the breed might not be in our dataset.")
    elif confidence > 0.8:
        st.success("High confidence prediction!")

    # Add some statistics
    st.subheader("Model Information")
    st.write(f"Total breeds in dataset: {len(class_names)}")
    st.write(f"Model accuracy: {class_info.get('final_accuracy', 'N/A')}")

import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps
import numpy as np
import json

# This function loads the pre-trained neural network model from a saved file
# The @st.cache decorator caches the function's output so it's only loaded once
@st.cache(allow_output_mutation=True)
def load_model():
    model = tf.keras.models.load_model('/content/drive/MyDrive/Emtech FINAL/final_improved_model.keras')
    return model

# This function loads the class information from the saved JSON file
@st.cache(allow_output_mutation=True)
def load_class_info():
    with open('/content/drive/MyDrive/Emtech FINAL/improved_class_info.json', 'r') as f:
        class_info = json.load(f)
    return class_info

# Load the pre-trained model and class information
model = load_model()
class_info = load_class_info()
class_names = class_info['class_names']
IMG_HEIGHT = class_info['img_height']
IMG_WIDTH = class_info['img_width']

# Display the application title
st.write("""
# Dog Breed Classification System
""")

# Create a file uploader widget for the user to upload an image file
file = st.file_uploader("Choose a dog photo from your computer", type=["jpg", "jpeg", "png"])

# This function takes the uploaded image data and the pre-trained model as input,
# preprocesses the image, and makes a prediction using the model
def import_and_predict(image_data, model):
    # Resize the image to match the model's expected input size
    size = (IMG_WIDTH, IMG_HEIGHT)
    image = ImageOps.fit(image_data, size, Image.LANCZOS)

    # Convert the image to a numpy array
    img = np.asarray(image)

    # Preprocess the image for EfficientNet model (scale pixel values appropriately)
    img = tf.keras.applications.efficientnet.preprocess_input(img)

    # Add a batch dimension to the image array
    img_reshape = img[np.newaxis, ...]

    # Make prediction using the pre-trained model
    prediction = model.predict(img_reshape)

    return prediction

if file is None:
    st.text("Please upload an image file")
else:
    # Open and display the uploaded image
    image = Image.open(file)
    st.image(image, use_column_width=True)

    # Make prediction on the uploaded image
    prediction = import_and_predict(image, model)

    # The class_names list contains the names of all 70 dog breeds that the model can predict
    class_names = class_info['class_names']

    # Find the predicted class with the highest probability and get the corresponding breed name
    string = "PREDICTED BREED: " + class_names[np.argmax(prediction)]

    # Display the predicted dog breed as output
    st.success(string)

    # Display confidence score
    confidence = np.max(prediction)
    st.info(f"Confidence: {confidence:.4f} ({confidence*100:.2f}%)")

    # Show top 3 predictions
    st.subheader("Top 3 Predictions:")
    top_3_indices = np.argsort(prediction[0])[-3:][::-1]
    for i, idx in enumerate(top_3_indices):
        breed_name = class_names[idx]
        breed_confidence = prediction[0][idx]
        st.write(f"{i+1}. {breed_name}: {breed_confidence:.4f}")